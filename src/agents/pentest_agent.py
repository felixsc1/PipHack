"""
LangGraph Agent for Penetration Testing Workflow
"""

import os
from typing import TypedDict, Annotated, Sequence, List
from operator import add

from dotenv import load_dotenv
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langgraph.graph import END, StateGraph
from langgraph.prebuilt import create_react_agent

from tools.shell_tool import execute_shell_command
from tools.file_tools import read_file, write_file, list_directory
from tools.tavily_tool import web_search

# Load environment variables
load_dotenv()

# Initialize the LLM
llm = ChatOpenAI(
    model="gpt-4-turbo-preview", temperature=0.1, api_key=os.getenv("OPENAI_API_KEY")
)


# Load context file for system prompt
def load_context():
    """Load the context file content for inclusion in system prompt."""
    context_path = os.path.join(
        os.path.dirname(__file__), "..", "..", "config", "context.md"
    )
    try:
        with open(context_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return "# Context file not found. Create config/context.md to provide custom wordlists and commands."
    except Exception as e:
        return f"# Error loading context: {str(e)}"


# Define the tools available to the agent
tools = [execute_shell_command, read_file, write_file, list_directory, web_search]


class AgentState(TypedDict):
    """State for the penetration testing agent."""

    messages: Annotated[Sequence[BaseMessage], add]
    scan_results: dict  # Store scan results for reference
    current_target: str  # Current target being analyzed
    next_action: str  # Next recommended action


def create_pentest_agent():
    """
    Create a LangGraph agent for penetration testing workflows.

    Returns:
        Compiled LangGraph for the pentesting agent
    """

    # Load context for the system prompt
    context_content = load_context()

    system_prompt = f"""You are PipHack, an intelligent penetration testing assistant designed to help security professionals and ethical hackers perform comprehensive security assessments.

Your capabilities include:
- Executing any Kali Linux command via shell access
- Reading and writing files for data management
- Exploring the filesystem to locate tools and wordlists
- Web search for documentation and security research

WORKFLOW GUIDELINES:
1. When a user requests to scan or analyze a target, start with reconnaissance using shell commands
2. Use file operations to save important findings and read wordlists/configs
3. Consult the context file first for custom wordlists and command templates
4. Learn tool syntax using `man <tool>` or `<tool> --help` when needed
5. Explore directories with `ls` before assuming file paths
6. Use web search only as a last resort for documentation or CVE information
7. Always provide clear explanations of what you're doing and why
8. Suggest next steps based on findings, but let the user decide on exploitation

TOOL USAGE:
- Use execute_shell_command for ANY security tool or Kali command (nmap, gobuster, nikto, etc.)
- Use read_file to read wordlists, config files, command outputs, or manpages
- Use write_file to save notes, findings, scripts, or scan results
- Use list_directory to explore filesystem and find wordlists/tools
- Use web_search only when local resources are insufficient

CONTEXT INFORMATION:
{context_content}

RESPONSE STYLE:
- Be professional and security-focused
- Explain technical concepts clearly
- Highlight potential security risks
- Provide actionable recommendations
- Never attempt actual exploitation without explicit user permission
- Use the context information to provide better command suggestions

Always maintain ethical hacking principles and remind users to only test systems they have permission to assess."""

    # Create the prompt template with system message
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            ("placeholder", "{messages}"),
        ]
    )

    # Create the agent using create_react_agent
    agent = create_react_agent(llm, tools, prompt=prompt)

    return agent


def create_custom_pentest_graph():
    """
    Create a custom LangGraph with more control over the pentesting workflow.

    Returns:
        Compiled LangGraph for structured pentesting workflow
    """

    def agent_node(state: AgentState):
        """Main agent node that processes user input and decides on actions."""
        messages = state["messages"]
        agent = create_pentest_agent()

        # Process through the agent
        result = agent.invoke({"messages": messages})

        # Extract the last message (agent's response)
        last_message = result["messages"][-1]

        return {
            "messages": [last_message],
            "scan_results": state.get("scan_results", {}),
            "current_target": state.get("current_target", ""),
            "next_action": "continue",
        }

    def should_continue(state: AgentState):
        """Determine if the workflow should continue or end."""
        # For now, always continue (user can end conversation)
        return "continue"

    # Create the graph
    workflow = StateGraph(AgentState)

    # Add nodes
    workflow.add_node("agent", agent_node)

    # Add edges
    workflow.set_entry_point("agent")
    workflow.add_conditional_edges(
        "agent", should_continue, {"continue": "agent", "end": END}
    )

    # Compile the graph
    graph = workflow.compile()

    return graph


# Create instances for import
pentest_agent = create_pentest_agent()
pentest_graph = create_custom_pentest_graph()


def convert_messages_to_langchain(messages: list) -> List[BaseMessage]:
    """
    Convert Streamlit message format to LangChain message format.
    
    Args:
        messages: List of message dictionaries with "role" and "content" keys
        
    Returns:
        List of LangChain BaseMessage objects
    """
    langchain_messages = []
    for msg in messages:
        role = msg.get("role", "user")
        content = msg.get("content", "")
        
        if role == "user":
            langchain_messages.append(HumanMessage(content=content))
        elif role == "assistant":
            langchain_messages.append(AIMessage(content=content))
        # Ignore other roles or handle them if needed
    
    return langchain_messages


def run_pentest_query(query: str, target: str = "", message_history: list = None) -> dict:
    """
    Run a penetration testing query through the agent.

    Args:
        query: User's question or request
        target: Optional target specification
        message_history: Optional list of previous messages in Streamlit format
                        (dicts with "role" and "content" keys)

    Returns:
        Agent response with results
    """
    # Convert message history to LangChain format if provided
    if message_history:
        messages = convert_messages_to_langchain(message_history)
    else:
        # Fallback to just the current query if no history provided
        messages = [HumanMessage(content=query)]
    
    initial_state = {
        "messages": messages,
        "scan_results": {},
        "current_target": target,
        "next_action": "start",
    }

    # Use the simpler agent for now
    result = pentest_agent.invoke(initial_state)

    return result
